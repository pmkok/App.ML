{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d728c91b-9a4d-4a77-b72c-85b1bd09ac66",
   "metadata": {},
   "source": [
    "First of all we need to download the data. We'll use the GTSRB Training Images Set as our whole Dataset and divide it later to a training and test set. In order to get this Notebook working, you need to do the following steps:\n",
    "- Change the referencing folderpath to yours\n",
    "- install opencv via the terminal\n",
    "\n",
    "The Following tasks numbered in the cells (1., 2., 3., ...) are shown in the Table of Contents:\n",
    "\n",
    "1. Importing Librarys\n",
    "2. Downloading the Data\n",
    "3. Renaming the Data\n",
    "4. Extracting the HOG Features\n",
    "5. Split the Data and Train the model and evaluating - HOG -Random Forest\n",
    "6. Split the Data and Train the model and evaluating - HOG -Support Vector Machine\n",
    "7. Extracting the HUE Features\n",
    "8. Split the Data and Train the model and evaluating - HUE -Random Forest\n",
    "9. Split the Data and Train the model and evaluating - HUE -Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3875a9d8-d2dc-404b-835a-657b7ca21b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1.Importing Librarys\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import skimage.transform as transform\n",
    "import skimage.io\n",
    "import skimage.exposure\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import make_classification\n",
    "import cv2 # pls enter this command in your Terminal: pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193bae88-66d0-461f-9ee7-2b334b13ec6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# 2.Downloading the Data\n",
    "# URL of the dataset\n",
    "url = \"https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Save the downloaded file\n",
    "    with open(\"dataset.zip\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    # Extract the contents of the ZIP file\n",
    "    with zipfile.ZipFile(\"dataset.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"dataset_folder_train_images\")\n",
    "    \n",
    "    print(\"Dataset downloaded and extracted successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "697c245b-2ab0-4125-a706-24b093f4f337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.Renaming the Data\n",
    "# Renaming the datainfrastructure\n",
    "def rename_folders(folder_path):\n",
    "    for folder_name in os.listdir(folder_path):\n",
    "        folder_old_name = os.path.join(folder_path, folder_name)\n",
    "        folder_new_name = os.path.join(folder_path, str(int(folder_name)))\n",
    "        \n",
    "        # Rename the folder\n",
    "        os.rename(folder_old_name, folder_new_name)\n",
    "        \n",
    "# Be sure, to insert the right folderpath here!  \n",
    "rename_folders('/home/jovyan/ML Projekkkkt/App.ML/dataset_folder_train_images/GTSRB/Final_Training/Images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b09b85-178e-4d71-9812-15bec8c9f70f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.Extracting the HOG Features\n",
    "#read the dataset and put it in an array for HOG_features:\n",
    "def read_data_HOG(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for class_label in range(43):\n",
    "        class_folder = os.path.join(folder_path, str(class_label))\n",
    "        \n",
    "        for file_name in os.listdir(class_folder):\n",
    "            if file_name.endswith(\".ppm\"):\n",
    "                file_path = os.path.join(class_folder, file_name)\n",
    "                \n",
    "                # Code snippet for hogz\n",
    "                img = skimage.io.imread(file_path, plugin='matplotlib')\n",
    "                img_gray = skimage.color.rgb2gray(img)\n",
    "                reshaped_img = transform.resize(img_gray, (40, 40))\n",
    "                normalized_image = skimage.exposure.rescale_intensity(reshaped_img, in_range='image', out_range=(0, 1))\n",
    "                hog_features, hog_image = hog(normalized_image, orientations=8, pixels_per_cell=(6, 6), cells_per_block=(2, 2), visualize=True)\n",
    "                hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 5))\n",
    "                hog_features_array = hog_features.reshape(-1)\n",
    "                X.append(hog_features_array)\n",
    "                y.append(class_label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "folder_path_train = \"/home/jovyan/ML Projekkkkt/App.ML/dataset_folder_train_images/GTSRB/Final_Training/Images\"\n",
    "\n",
    "X_hog,y_hog = read_data_HOG(folder_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530fcdf5-5ccc-4a6f-90b9-0e257ac48ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 0.9422341239479725\n",
      "\n",
      "Class: 0\n",
      "Precision: 1.0\n",
      "Recall: 0.5526315789473685\n",
      "F1-Score: 0.711864406779661\n",
      "\n",
      "Class: 1\n",
      "Precision: 0.8961303462321792\n",
      "Recall: 0.8870967741935484\n",
      "F1-Score: 0.8915906788247213\n",
      "\n",
      "Class: 2\n",
      "Precision: 0.8329853862212944\n",
      "Recall: 0.8866666666666667\n",
      "F1-Score: 0.8589881593110872\n",
      "\n",
      "Class: 3\n",
      "Precision: 0.9375\n",
      "Recall: 0.9107142857142857\n",
      "F1-Score: 0.9239130434782609\n",
      "\n",
      "Class: 4\n",
      "Precision: 0.9140271493212669\n",
      "Recall: 0.9665071770334929\n",
      "F1-Score: 0.9395348837209303\n",
      "\n",
      "Class: 5\n",
      "Precision: 0.7864864864864864\n",
      "Recall: 0.7994505494505495\n",
      "F1-Score: 0.7929155313351498\n",
      "\n",
      "Class: 6\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Class: 7\n",
      "Precision: 0.8823529411764706\n",
      "Recall: 0.9172661870503597\n",
      "F1-Score: 0.8994708994708994\n",
      "\n",
      "Class: 8\n",
      "Precision: 0.9084249084249084\n",
      "Recall: 0.8239202657807309\n",
      "F1-Score: 0.8641114982578397\n",
      "\n",
      "Class: 9\n",
      "Precision: 0.981549815498155\n",
      "Recall: 0.9925373134328358\n",
      "F1-Score: 0.9870129870129871\n",
      "\n",
      "Class: 10\n",
      "Precision: 0.9631578947368421\n",
      "Recall: 0.9891891891891892\n",
      "F1-Score: 0.976\n",
      "\n",
      "Class: 11\n",
      "Precision: 0.8226950354609929\n",
      "Recall: 0.9830508474576272\n",
      "F1-Score: 0.8957528957528957\n",
      "\n",
      "Class: 12\n",
      "Precision: 0.9955654101995566\n",
      "Recall: 0.9977777777777778\n",
      "F1-Score: 0.9966703662597114\n",
      "\n",
      "Class: 13\n",
      "Precision: 0.9977777777777778\n",
      "Recall: 0.9933628318584071\n",
      "F1-Score: 0.9955654101995566\n",
      "\n",
      "Class: 14\n",
      "Precision: 1.0\n",
      "Recall: 0.9135802469135802\n",
      "F1-Score: 0.9548387096774192\n",
      "\n",
      "Class: 15\n",
      "Precision: 0.9917355371900827\n",
      "Recall: 1.0\n",
      "F1-Score: 0.995850622406639\n",
      "\n",
      "Class: 16\n",
      "Precision: 1.0\n",
      "Recall: 0.9888888888888889\n",
      "F1-Score: 0.9944134078212291\n",
      "\n",
      "Class: 17\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Class: 18\n",
      "Precision: 0.9778761061946902\n",
      "Recall: 0.9567099567099567\n",
      "F1-Score: 0.9671772428884026\n",
      "\n",
      "Class: 19\n",
      "Precision: 0.975609756097561\n",
      "Recall: 0.9302325581395349\n",
      "F1-Score: 0.9523809523809524\n",
      "\n",
      "Class: 20\n",
      "Precision: 0.9857142857142858\n",
      "Recall: 0.8846153846153846\n",
      "F1-Score: 0.9324324324324325\n",
      "\n",
      "Class: 21\n",
      "Precision: 1.0\n",
      "Recall: 0.9523809523809523\n",
      "F1-Score: 0.975609756097561\n",
      "\n",
      "Class: 22\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Class: 23\n",
      "Precision: 0.9907407407407407\n",
      "Recall: 0.981651376146789\n",
      "F1-Score: 0.9861751152073732\n",
      "\n",
      "Class: 24\n",
      "Precision: 1.0\n",
      "Recall: 0.8813559322033898\n",
      "F1-Score: 0.936936936936937\n",
      "\n",
      "Class: 25\n",
      "Precision: 0.9245283018867925\n",
      "Recall: 0.9865771812080537\n",
      "F1-Score: 0.9545454545454546\n",
      "\n",
      "Class: 26\n",
      "Precision: 0.9137931034482759\n",
      "Recall: 0.8688524590163934\n",
      "F1-Score: 0.8907563025210085\n",
      "\n",
      "Class: 27\n",
      "Precision: 1.0\n",
      "Recall: 0.7872340425531915\n",
      "F1-Score: 0.880952380952381\n",
      "\n",
      "Class: 28\n",
      "Precision: 0.9651162790697675\n",
      "Recall: 0.8383838383838383\n",
      "F1-Score: 0.8972972972972972\n",
      "\n",
      "Class: 29\n",
      "Precision: 1.0\n",
      "Recall: 0.8813559322033898\n",
      "F1-Score: 0.936936936936937\n",
      "\n",
      "Class: 30\n",
      "Precision: 0.9555555555555556\n",
      "Recall: 0.9052631578947369\n",
      "F1-Score: 0.9297297297297298\n",
      "\n",
      "Class: 31\n",
      "Precision: 0.9937888198757764\n",
      "Recall: 1.0\n",
      "F1-Score: 0.9968847352024921\n",
      "\n",
      "Class: 32\n",
      "Precision: 0.9761904761904762\n",
      "Recall: 1.0\n",
      "F1-Score: 0.9879518072289156\n",
      "\n",
      "Class: 33\n",
      "Precision: 0.9785714285714285\n",
      "Recall: 0.9927536231884058\n",
      "F1-Score: 0.9856115107913668\n",
      "\n",
      "Class: 34\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Class: 35\n",
      "Precision: 0.9955156950672646\n",
      "Recall: 0.9910714285714286\n",
      "F1-Score: 0.9932885906040269\n",
      "\n",
      "Class: 36\n",
      "Precision: 1.0\n",
      "Recall: 0.9875\n",
      "F1-Score: 0.9937106918238994\n",
      "\n",
      "Class: 37\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Class: 38\n",
      "Precision: 0.9975786924939467\n",
      "Recall: 0.9856459330143541\n",
      "F1-Score: 0.9915764139590855\n",
      "\n",
      "Class: 39\n",
      "Precision: 1.0\n",
      "Recall: 0.9827586206896551\n",
      "F1-Score: 0.9913043478260869\n",
      "\n",
      "Class: 40\n",
      "Precision: 1.0\n",
      "Recall: 0.9666666666666667\n",
      "F1-Score: 0.983050847457627\n",
      "\n",
      "Class: 41\n",
      "Precision: 1.0\n",
      "Recall: 0.9574468085106383\n",
      "F1-Score: 0.9782608695652174\n",
      "\n",
      "Class: 42\n",
      "Precision: 1.0\n",
      "Recall: 0.975609756097561\n",
      "F1-Score: 0.9876543209876543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.Split the Data and Train the model and evaluating - HOG - Random Forest\n",
    "#random Forest for HOG_Features\n",
    "X_train_forest_hog, X_test_forest_hog, y_train_forest_hog, y_test_forest_hog = train_test_split(X_hog, y_hog, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_forest_hog = scaler.fit_transform(X_train_forest_hog)\n",
    "X_test_scaled_forest_hog = scaler.transform(X_test_forest_hog)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "random_forest_hog = RandomForestClassifier()\n",
    "random_forest_hog.fit(X_train_scaled_forest_hog, y_train_forest_hog)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_forest_hog = random_forest_hog.predict(X_test_scaled_forest_hog)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_forest_hog = accuracy_score(y_test_forest_hog, y_pred_forest_hog)\n",
    "print(\"Accuracy for Random Forest:\", accuracy_forest_hog)\n",
    "print()\n",
    "\n",
    "# Calculating precision, recall, and F1-score for each class\n",
    "precision_forest_hog = precision_score(y_test_forest_hog, y_pred_forest_hog, average=None)\n",
    "recall_forest_hog = recall_score(y_test_forest_hog, y_pred_forest_hog, average=None)\n",
    "f1_forest_hog = f1_score(y_test_forest_hog, y_pred_forest_hog, average=None)\n",
    "\n",
    "# Printing the evaluation metrics for each class\n",
    "for class_label, prec, rec, f1_score_rf1 in zip(np.unique(y_hog), precision_forest_hog, recall_forest_hog, f1_forest_hog):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F1-Score: {f1_score_rf1}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ea0a6d-9fa0-4a63-94b2-87201d246d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for a SVM: 0.9802346340219332\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m precision_svm_hog \u001b[38;5;241m=\u001b[39m precision_score(y_test_svm_hog, y_pred_svm_hog, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m recall_svm_hog \u001b[38;5;241m=\u001b[39m recall_score(y_test_svm_hog, y_pred_svm_hog, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m f1_svm_hog \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_svm_hog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_svm_hog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Printing the evaluation metrics for each class\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_label, prec, rec, f1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_hog), precision_svm_hog, recall_svm_hog, f1_svm_hog):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "# 6.Split the Data and Train the model and evaluating - HOG - Support Vector Machine\n",
    "#SVM for HOG_Features\n",
    "X_train_svm_hog, X_test_svm_hog, y_train_svm_hog, y_test_svm_hog = train_test_split(X_hog, y_hog, test_size=0.2, random_state=42)\n",
    "\n",
    "clf_hog= make_pipeline(StandardScaler(),SVC(kernel=\"rbf\", gamma= \"auto\"))\n",
    "clf_hog.fit(X_train_svm_hog,y_train_svm_hog)\n",
    "y_pred_svm_hog = clf_hog.predict(X_test_svm_hog)\n",
    "accuracy_svm_hog = accuracy_score(y_test_svm_hog, y_pred_svm_hog)\n",
    "print(\"Accuracy for a SVM:\", accuracy_svm_hog)\n",
    "print()\n",
    "\n",
    "# Calculating precision, recall, and F1-score for each class\n",
    "precision_svm_hog = precision_score(y_test_svm_hog, y_pred_svm_hog, average=None)\n",
    "recall_svm_hog = recall_score(y_test_svm_hog, y_pred_svm_hog, average=None)\n",
    "f1_svm_hog = f1_score(y_test_svm_hog, y_pred_svm_hog, average=None)\n",
    "\n",
    "# Printing the evaluation metrics for each class\n",
    "for class_label, prec, rec, f1_score_svm1  in zip(np.unique(y_hog), precision_svm_hog, recall_svm_hog, f1_svm_hog):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F1-Score: {f1_score_svm1}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84a34e-1442-4572-b7a2-155d267e908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.Extracting the HUE Features\n",
    "def read_data_HUE(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    desired_width = 29\n",
    "    desired_height = 30\n",
    "\n",
    "    for class_label in range(43):\n",
    "        class_folder = os.path.join(folder_path, str(class_label))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for file_name in os.listdir(class_folder):\n",
    "            if file_name.endswith(\".ppm\"):\n",
    "                file_path = os.path.join(class_folder, file_name)\n",
    "                \n",
    "                \n",
    "            \n",
    "                image = cv2.imread(file_path)\n",
    "                scaled_image = cv2.resize(image, (desired_width, desired_height)) \n",
    "                image_hsv = cv2.cvtColor(scaled_image, cv2.COLOR_BGR2HSV) \n",
    "                \n",
    "                border_size = 5\n",
    "                image_hsv_cropped = image_hsv[border_size:-border_size, border_size:-border_size] \n",
    "                hue_values = image_hsv_cropped[:, :, 0].flatten()\n",
    "                \n",
    "                histogram, _ = np.histogram(hue_values, bins=256, range=[0, 256])\n",
    "                normalized_histogram = histogram.astype(np.float64) / np.sum(histogram)\n",
    "                dimensionality = len(normalized_histogram)\n",
    "               \n",
    "                \n",
    "                X.append(hue_values)\n",
    "                y.append(class_label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "folder_path_train = \"/home/jovyan/ML Projekkkkt/App.ML/dataset_folder_train_images/GTSRB/Final_Training/Images\"\n",
    "\n",
    "X_hue,y_hue = read_data_HUE(folder_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60ba53-ad18-4a9f-9347-42719475e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.Split the Data and Train the model and evaluating - HUE - Random Forest\n",
    "#random Forest for HUE features\n",
    "X_train_forest_hue, X_test_forest_hue, y_train_forest_hue, y_test_forest_hue = train_test_split(X_hue, y_hue, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_forest_hue = scaler.fit_transform(X_train_forest_hue)\n",
    "X_test_scaled_forest_hue = scaler.transform(X_test_forest_hue)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "random_forest_hue = RandomForestClassifier()\n",
    "random_forest_hue.fit(X_train_scaled_forest_hue, y_train_forest_hue)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_forest_hue = random_forest_hue.predict(X_test_scaled_forest_hue)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_forest_hue = accuracy_score(y_test_forest_hue, y_pred_forest_hue)\n",
    "print(\"Accuracy for Random Forest:\", accuracy_forest_hue)\n",
    "print()\n",
    "\n",
    "# Calculating precision, recall, and F1-score for each class\n",
    "precision_forest_hue = precision_score(y_test_forest_hue, y_pred_forest_hue, average=None)\n",
    "recall_forest_hue = recall_score(y_test_forest_hue, y_pred_forest_hue, average=None)\n",
    "f1_forest_hue = f1_score(y_test_forest_hue, y_pred_forest_hue, average=None)\n",
    "\n",
    "# Printing the evaluation metrics for each class\n",
    "for class_label, prec, rec, f1_score_rf2 in zip(np.unique(y_hue), precision_forest_hue, recall_forest_hue, f1_forest_hue):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F1-Score: {f1_score_rf2}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cec566-68d2-4246-b512-7e36cdcda6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.Split the Data and Train the model and evaluating - HUE - Support Vector Machine\n",
    "#SVM for HUE features\n",
    "X_train_svm_hue, X_test_svm_hue, y_train_svm_hue, y_test_svm_hue = train_test_split(X_hue, y_hue, test_size=0.2, random_state=42)\n",
    "\n",
    "clf_hue= make_pipeline(StandardScaler(),SVC(kernel=\"rbf\", gamma= \"auto\"))\n",
    "clf_hue.fit(X_train_svm_hue,y_train_svm_hue)\n",
    "y_pred_svm_hue = clf_hue.predict(X_test_svm_hue)\n",
    "accuracy_svm_hue = accuracy_score(y_test_svm_hue, y_pred_svm_hue)\n",
    "print(\"Accuracy for a SVM:\", accuracy_svm_hue)\n",
    "print()\n",
    "\n",
    "# Calculating precision, recall, and F1-score for each class\n",
    "precision_svm_hue = precision_score(y_test_svm_hue, y_pred_svm_hue, average=None)\n",
    "recall_svm_hue = recall_score(y_test_svm_hue, y_pred_svm_hue, average=None)\n",
    "f1_svm_hue = f1_score(y_test_svm_hue, y_pred_svm_hue, average=None)\n",
    "\n",
    "# Printing the evaluation metrics for each class\n",
    "for class_label, prec, rec, f1_score_svm2 in zip(np.unique(y_hue), precision_svm_hue, recall_svm_hue, f1_svm_hue):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F1-Score: {f1_score_svm2}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
