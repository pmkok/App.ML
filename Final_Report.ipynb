{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192e6f52-faed-4116-9816-240b09ec95f6",
   "metadata": {},
   "source": [
    "# Silly Signs Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad86eb8-90bb-48d3-8721-eb35450ec949",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Related Work](#RelatedWork)\n",
    "3. [Problem](#Problem)\n",
    "4. [Methods/Model Selection](#Methods)\n",
    "5. [Experiments/Results/Discussion](#Discussion)\n",
    "6. [Conclusion](#Conclusion)\n",
    "7. [References](#References)\n",
    "8. [Installation](#Install)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633d361-737d-4606-9f31-04a1d76c2896",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "Artificial Intelligence (AI) has emerged as a powerful tool for solving complex problems and transforming various industries. Its ability to process large volumes of data, learn from patterns, and make intelligent decisions has made it a valuable asset in problem-solving scenarios. AI offers several advantages that enable the resolution of problems in a simpler and more efficient manner. One of the key strengths of AI is its capacity to handle and analyze massive amounts of data quickly and accurately. Traditional problem-solving approaches often struggle with large datasets or complex patterns that are difficult for humans to comprehend. AI algorithms, on the other hand, can effortlessly process and extract valuable insights from vast data sets, enabling the identification of hidden patterns or correlations that might not be evident to human observers. This capability allows AI to tackle complex problems with ease.\n",
    "\n",
    "As autonomous driving gains prominence in our era, it is curial to ensure its reliability. To gain insight into autonomous driving, we aim to develop a machine learning model, which can accurately identify German traffic signs.\n",
    "Accurate traffic sign recognition is critical or ensuring safe and efficient transportation. It is not advisable to rely solely on the maps of navigation devices. Maps can be outdated or due to factors such as construction sites, road signage can change spontaneously. By incorporating image recognition, cameras can be used to capture real-time visual data of the road\n",
    "and traffic conditions. This data can then be processed using machine learning algorithms to analyze and interpret the information. \n",
    "\n",
    "In this Project we will use the SVM and a Random Forest Model, feeded with extracted features of the traffic signs pictures HOG and HUE features. We will look how the models and features differntiate to each other and try to understand why it could differ from each other. Lastly, we will compare our findings with the outcomes of a competition that employed the same dataset as the one we used.\n",
    "\n",
    "\n",
    "## Related Work <a name=\"RelatedWork\"></a>\n",
    "\n",
    "During our research, we came across a sign classification dataset, which coincidentally had a competition associated with it. This presented us with an opportunity to compare our results with those of other competitors. It was to note that the leading participants in the competition predominantly used Convolutional Neural Network (CNN) models. This led us to question how the task could be accomplished using the models covered in our course. Additionally, we observed that some competitors on the leaderboard achieved success by using Random Forest or SVM models. Additionally surpassing their performance poses an exciting challenge for us.\n",
    "\n",
    "With the example project in the course already finished, it was a great possibility to check back on it and use snippets of it. The \"Hands-On Machine Learning\" Book which we're using in the course is also great to get some ideas from it and learn how to build a machine learning algorithm. While the book mainly uses Scikit-Learn we decided to use the libary too, beacuase of it's great examples, glossary and easy to use functions.\n",
    "\n",
    "\n",
    "## Problem <a name=\"Problem\"></a>\n",
    "\n",
    "The accurate detection and interpretation of road signs play a vital role in ensuring road safety and efficient traffic management. (However, traditional methods of road sign recognition often face challenges in handling the diverse range of signs, varying environmental conditions, and real-time processing requirements.) This necessitates the exploration of AI-based solutions to overcome these limitations and enhance road sign recognition capabilities. AI-powered road sign recognition systems can effectively address the complexity and variability of road signs. The problem lies in the diverse shapes, colors, sizes, and designs of road signs, making it challenging for traditional algorithms to accurately detect and classify them. AI, specifically machine learning algorithms, can learn intricate patterns and features from large datasets, enabling the development of robust models capable of accurately identifying and classifying various types of road signs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e5194-6a32-416c-bb09-8b7f005ed86b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Methods/Model Selection <a name=\"Methods\"></a>\n",
    "\n",
    "In the Project, we opted for the utilization of two models: Support Vector Machine (SVM) and Random Forest Tree. These models were previously explored in our course and demonstrated contrasting behaviors, prompting us to highlight the significance of selecting the right model.\n",
    "\n",
    "Given a dataset only having images, the first step is to obtain numerical representations of these images to use them in machine learning models. Upon visiting the website, we discovered that certain features (such as HOG, Hue, and HAAR-Like) had already been extracted. Nonetheless, we decided to extract these features ourselves and to align with the available data. However, throughout the course of the project, we encountered difficulties in extracting and utilizing the HAAR-Like features, so we don't deal with them any further.\n",
    "\n",
    "The Random Forest Tree is an ensemble of decisions trees, it aggregates the predictions from the individual decision trees using voting or averaging to get it's best results.\n",
    "It's a very common and highly robust model for using a multi-classification problem.\n",
    "\n",
    "To classify the extracted features, Support Vector Machines (SVM) are commonly employed. SVM is a powerful machine learning algorithm that can efficiently categorize data points based on their features. By training an SVM model with labeled road sign images and their corresponding extracted features, the system can learn to accurately classify unseen road signs based on the learned patterns and feature representations.\n",
    "\n",
    "In the realm of road sign recognition, advancements in computer vision techniques have paved the way for effective detection and classification methods. One such approach involves the utilization of features like Hue and Histogram of Oriented Gradients (HOG) features, coupled with Support Vector Machine (SVM) and the random forest algorthm.\n",
    "\n",
    "Hue is a color attribute that represents the dominant color in an image. By extracting the hue component from road sign images, we can leverage its distinctive characteristics to differentiate between different types of signs. This feature provides valuable information for the classification process, aiding in accurate recognition.\n",
    "\n",
    "The Histogram of Oriented Gradients (HOG) technique captures the distribution of gradient orientations within an image. By analyzing the intensity gradients, HOG can effectively capture the shape and edges of road signs. These features serve as strong discriminative cues, enabling the system to identify and classify signs based on their unique shapes and contours.\n",
    "\n",
    "\n",
    "## Experiments/Results/Discussion <a name=\"Discussion\"></a>\n",
    "\n",
    "To using only a jupyter notebook we implemented a way to be able to download the data and use them only from the jupyter notebook. While extracting the features and try to use them, we stepped on an error not be able to use the data downloaded because of it's properly naming. The datafolders have to be ascending from 0 to the total number of classes (43), but our dataset was named with additional zeros (0001), so we write a function to rename them.\n",
    "After extracting the numerical values from the pictures, we created an array to store the values. Important now is to assign each numerical feature to it's class label. So we assigned the class label in an array. This was good to apply, because the pictures were stored in the folder for the corresponding class.\n",
    "\n",
    "For the HOG-Features we decided to transform the picture into gray color to simplify the computation because there are less dimensions (red, green, blue transform to gray). We also thought, that by removing the color information, the feature extraction can focus more on the shape and edge information. We also had to reshape the images, because the HOG feature extraction involves dividing the images into cells and computing then the gradient orientationts within the cell. To get good results it makes sense to have the same shape of all pictures. After reshaping the images, the pictures get normalized by the function from skimage rescale_intensity. With now an constant input we used the ouput_range(0,1) to ensure that our pixel range is standardized and to enhance our contrast in the image. The prepared images could now be used to extract the HOG features. To get the right parameters for the HOG extraction we used one example image and visualized it, so we could see the effects of the different parameters. We observed our numerical features and compared it with the HOG features availble from the dataset and tuned it until we have reached similiar values.\n",
    "\n",
    "The Hue feature extraction was done with the OpenCV libary having advantageous functions for color images. Here the images were reshaped too and the color scheme was converted from RBG to a HSV colorspace with a 256-bin histogram of hue values. Here we orientaded us to the availble dataset we already got.\n",
    "It makes sense to convert the RBG color scheme into HSV (which is visualized below) to have a larger set of colors to not underfit our classification.\n",
    "\n",
    "![HSV color range](https://docs.opencv.org/4.x/colorscale_hsv.jpg)\n",
    "\n",
    "For the dataset partitioning we decided to split up our downloaded data to 80 percent training data and 20 percent test data. With having over 50000 images we think it should be enough data to to split it up and train our model with it. However we didn't made sure, that pictures from every class are in the test and training data, but the given size of the data it is very likley that this is the case.\n",
    "\n",
    "Beside it's not necessary to scale the data for the random forest algorithm we decided to do it anyways, to speed up the computation and to be sure that features with larger scales don't influence the algorithm more than they should.\n",
    "\n",
    "Compared to the random forest algorithm it's important for the SVM that we scale our data. To repoduce the our results we added a random_state to be ensure that we got almost the same results (the test and training data differs each time we start from the beginning). For using a SVM for a multiclassification we applied a kernel. With the \"kernel trick\" we can transform our input feature space into a higher dimension, to let the SVM create decision boundaries that can discriminate between multiple classes.\n",
    "For the kernel we used the gaussian RBF kernel, it's the most common used and is very flexible, it can also create nonlinear boundaries. The parameter gamma is set to \"auto\", because of the data size it would take quite some time to figure out the optmial gamma parameter.\n",
    "\n",
    "To get the results of the models we determined the overall accuracy ((True Positives + True Negatives) / (Positives + Negatives)), which considers the overall correctness of predictions across all classes. In addition we calculated Precision, Recall and the F1-Score for each class separately. Especially the precision is crucial for our problem case, because we don't want to classify a 20 km/h speed limitation as 120 km/h speed limit. \n",
    "\n",
    "Accuracy  over all  classes:\n",
    "| Feature | SVM | Random Forest |\n",
    "|----------|----------|----------|\n",
    "|  HOG  |  98%  | 94.5%  |\n",
    "|  HUE  | 57.9%  | 74.7%  |\n",
    "\n",
    "With the leaderborad some competitors using a SVM around 96% and with the random forest around 95% we got roughly the same results. We can't compare the results directly, because of that our test data is different from the one used in the competition.\n",
    "\n",
    "The results of the SVM and the random forest are a bit diffrent. It might be, that the random forest is overfitting, because we didn't regularized it. The SVM might suffer from the \"auto\" set gamma parameter, so the decision boundary is not optimal.\n",
    "\n",
    "A plausible result is, that the results from the Hue features are significantly worse. This is because many street signs are counstructed in a similar way and can't be distinguished very much by the colors.\n",
    "\n",
    "## Conclusion <a name=\"Conclusion\"></a>\n",
    "\n",
    "An important point in addition to the right model are the right features. As we see in our results and in the referenced competition, multiple models can produce almost the same results. Understanding the main problem is essential to program and picking the right machine learning algorithm.\n",
    "\n",
    "For forthcoming endeavors, it would be advantageous to expand the database to encompass European street signs, rather than being restricted to German street signs. Also a confusion Matric might be better for visulazing the results. Additionally, the inclusion of bicycle traffic signs in the dataset is also feasible.\n",
    "\n",
    "The Project was very fun to make, but very hard to start from scratch and picking an appropriate problem to solve can also be challenging. But throughout the project and in addition with the course Appl. Machine Learning and ML Basics we've learned a lot.\n",
    "\n",
    "## References <a name=\"References\"></a>\n",
    "\n",
    "Leaderboard from the competition: https://benchmark.ini.rub.de/gtsrb_results_ijcnn.html\n",
    "\n",
    "For programming and solutionfinding we partly used ChatGPT, therefore we always took our time to verify the correctness of its answers.\n",
    "It's very important to check the responses of an Chatbot to minimize the errors and to really understand the answer. \n",
    "\n",
    "https://scikit-learn.org\n",
    "\n",
    "https://scikit-image.org\n",
    "\n",
    "https://docs.opencv.org\n",
    "\n",
    "https://chat.openai.com\n",
    "\n",
    "https://benchmark.ini.rub.de/gtsrb_dataset.html\n",
    "\n",
    "J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The German Traffic Sign Recognition Benchmark: A multi-class classification competition. In Proceedings of the IEEE International Joint Conference on Neural Networks, pages 1453–1460. 2011.\n",
    "\n",
    "Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Third Edition, O'Reilly, Aurélien Géron, October 2022\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728c91b-9a4d-4a77-b72c-85b1bd09ac66",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Installation <a name=\"Install\"></a>\n",
    "\n",
    "\n",
    "First of all we need to download the data. We'll use the GTSRB Training Images Set as our whole Dataset and divide it later to a training and test set. In order to get this Notebook working, you need to do the following steps:\n",
    "- Change the referencing folderpath to yours\n",
    "- install opencv via the terminal (pip3 install opencv-python)\n",
    "\n",
    "The Following tasks numbered in the cells (1., 2., 3., ...) are shown in the following Table:\n",
    "\n",
    "1. Importing Librarys\n",
    "2. Downloading the Data\n",
    "3. Renaming the Data\n",
    "4. Extracting the HOG Features\n",
    "5. Split the Data and Train the model and evaluating - HOG -Random Forest\n",
    "6. Split the Data and Train the model and evaluating - HOG -Support Vector Machine\n",
    "7. Extracting the HUE Features\n",
    "8. Split the Data and Train the model and evaluating - HUE -Random Forest\n",
    "9. Split the Data and Train the model and evaluating - HUE -Support Vector Machine\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3875a9d8-d2dc-404b-835a-657b7ca21b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1.Importing Librarys\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import skimage.transform as transform\n",
    "import skimage.io\n",
    "import skimage.exposure\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import make_classification\n",
    "import cv2 # pls enter this command in your Terminal: pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193bae88-66d0-461f-9ee7-2b334b13ec6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# 2.Downloading the Data\n",
    "# URL of the dataset\n",
    "url = \"https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Save the downloaded file\n",
    "    with open(\"dataset.zip\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    # Extract the contents of the ZIP file\n",
    "    with zipfile.ZipFile(\"dataset.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"dataset_folder_train_images\")\n",
    "    \n",
    "    print(\"Dataset downloaded and extracted successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "697c245b-2ab0-4125-a706-24b093f4f337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.Renaming the Data\n",
    "# Renaming the datainfrastructure\n",
    "def rename_folders(folder_path):\n",
    "    for folder_name in os.listdir(folder_path):\n",
    "        folder_old_name = os.path.join(folder_path, folder_name)\n",
    "        folder_new_name = os.path.join(folder_path, str(int(folder_name)))\n",
    "        \n",
    "        # Rename the folder\n",
    "        os.rename(folder_old_name, folder_new_name)\n",
    "        \n",
    "# Be sure, to insert the right folderpath here!  \n",
    "rename_folders('/home/jovyan/ML Projekkkkt/App.ML/dataset_folder_train_images/GTSRB/Final_Training/Images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b09b85-178e-4d71-9812-15bec8c9f70f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.Extracting the HOG Features\n",
    "#read the dataset and put it in an array for HOG_features:\n",
    "def read_data_HOG(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for class_label in range(43):\n",
    "        class_folder = os.path.join(folder_path, str(class_label))\n",
    "        \n",
    "        for file_name in os.listdir(class_folder):\n",
    "            if file_name.endswith(\".ppm\"):\n",
    "                file_path = os.path.join(class_folder, file_name)\n",
    "                \n",
    "                # Code snippet for hogz\n",
    "                img = skimage.io.imread(file_path, plugin='matplotlib')\n",
    "                img_gray = skimage.color.rgb2gray(img)\n",
    "                reshaped_img = transform.resize(img_gray, (40, 40))\n",
    "                normalized_image = skimage.exposure.rescale_intensity(reshaped_img, in_range='image', out_range=(0, 1))\n",
    "                hog_features, hog_image = hog(normalized_image, orientations=8, pixels_per_cell=(6, 6), cells_per_block=(2, 2), visualize=True)\n",
    "                hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 5))\n",
    "                hog_features_array = hog_features.reshape(-1)\n",
    "                X.append(hog_features_array)\n",
    "                y.append(class_label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "folder_path_train = \"/home/jovyan/ML Projekkkkt/App.ML/dataset_folder_train_images/GTSRB/Final_Training/Images\"\n",
    "\n",
    "X_hog,y_hog = read_data_HOG(folder_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530fcdf5-5ccc-4a6f-90b9-0e257ac48ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 0.9422341239479725\n",
      "\n",
      "Class: 0\n",
      "Precision: 1.0\n",
      "Recall: 0.5526315789473685\n",
      "F1-Score: 0.711864406779661\n",
      "\n",
      "Class: 1\n",
      "Precision: 0.8961303462321792\n",
      "Recall: 0.8870967741935484\n",
      "F1-Score: 0.8915906788247213\n",
      "\n",
      "Class: 2\n",
      "Precision: 0.8329853862212944\n",
      "Recall: 0.8866666666666667\n",
      "F1-Score: 0.8589881593110872\n",
      "\n",
      "Class: 3\n",
      "Precision: 0.9375\n",
      "Recall: 0.9107142857142857\n",
      "F1-Score: 0.9239130434782609\n",
      "\n",
      "Class: 4\n",
      "Precision: 0.9140271493212669\n",
      "Recall: 0.9665071770334929\n",
      "F1-Score: 0.9395348837209303\n",
      "\n",
      "Class: 5\n",
      "Precision: 0.7864864864864864\n",
      "Recall: 0.7994505494505495\n",
      "F1-Score: 0.7929155313351498\n",
      "\n",
      "Class: 6\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Class: 7\n",
      "Precision: 0.8823529411764706\n",
      "Recall: 0.9172661870503597\n",
      "F1-Score: 0.8994708994708994\n",
      "\n",
      "Class: 8\n",
      "Precision: 0.9084249084249084\n",
      "Recall: 0.8239202657807309\n",
      "F1-Score: 0.8641114982578397\n",
      "\n",
      "Class: 9\n",
      "Precision: 0.981549815498155\n",
      "Recall: 0.9925373134328358\n",
      "F1-Score: 0.9870129870129871\n",
      "\n",
      "Class: 10\n",
      "Precision: 0.9631578947368421\n",
      "Recall: 0.9891891891891892\n",
      "F1-Score: 0.976\n",
      "\n",
      "Class: 11\n",
      "Precision: 0.8226950354609929\n",
      "Recall: 0.9830508474576272\n",
      "F1-Score: 0.8957528957528957\n",
      "\n",
      "Class: 12\n",
      "Precision: 0.9955654101995566\n",
      "Recall: 0.9977777777777778\n",
      "F1-Score: 0.9966703662597114\n",
      "\n",
      "Class: 13\n",
      "Precision: 0.9977777777777778\n",
      "Recall: 0.9933628318584071\n",
      "F1-Score: 0.9955654101995566\n",
      "\n",
      "Class: 14\n",
      "Precision: 1.0\n",
      "Recall: 0.9135802469135802\n",
      "F1-Score: 0.9548387096774192\n",
      "\n",
      "Class: 15\n",
      "Precision: 0.9917355371900827\n",
      "Recall: 1.0\n",
      "F1-Score: 0.995850622406639\n",
      "\n",
      "Class: 16\n",
      "Precision: 1.0\n",
      "Recall: 0.9888888888888889\n",
      "F1-Score: 0.9944134078212291\n",
      "\n",
      "Class: 17\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Class: 18\n",
      "Precision: 0.9778761061946902\n",
      "Recall: 0.9567099567099567\n",
      "F1-Score: 0.9671772428884026\n",
      "\n",
      "Class: 19\n",
      "Precision: 0.975609756097561\n",
      "Recall: 0.9302325581395349\n",
      "F1-Score: 0.9523809523809524\n",
      "\n",
      "Class: 20\n",
      "Precision: 0.9857142857142858\n",
      "Recall: 0.8846153846153846\n",
      "F1-Score: 0.9324324324324325\n",
      "\n",
      "Class: 21\n",
      "Precision: 1.0\n",
      "Recall: 0.9523809523809523\n",
      "F1-Score: 0.975609756097561\n",
      "\n",
      "Class: 22\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Class: 23\n",
      "Precision: 0.9907407407407407\n",
      "Recall: 0.981651376146789\n",
      "F1-Score: 0.9861751152073732\n",
      "\n",
      "Class: 24\n",
      "Precision: 1.0\n",
      "Recall: 0.8813559322033898\n",
      "F1-Score: 0.936936936936937\n",
      "\n",
      "Class: 25\n",
      "Precision: 0.9245283018867925\n",
      "Recall: 0.9865771812080537\n",
      "F1-Score: 0.9545454545454546\n",
      "\n",
      "Class: 26\n",
      "Precision: 0.9137931034482759\n",
      "Recall: 0.8688524590163934\n",
      "F1-Score: 0.8907563025210085\n",
      "\n",
      "Class: 27\n",
      "Precision: 1.0\n",
      "Recall: 0.7872340425531915\n",
      "F1-Score: 0.880952380952381\n",
      "\n",
      "Class: 28\n",
      "Precision: 0.9651162790697675\n",
      "Recall: 0.8383838383838383\n",
      "F1-Score: 0.8972972972972972\n",
      "\n",
      "Class: 29\n",
      "Precision: 1.0\n",
      "Recall: 0.8813559322033898\n",
      "F1-Score: 0.936936936936937\n",
      "\n",
      "Class: 30\n",
      "Precision: 0.9555555555555556\n",
      "Recall: 0.9052631578947369\n",
      "F1-Score: 0.9297297297297298\n",
      "\n",
      "Class: 31\n",
      "Precision: 0.9937888198757764\n",
      "Recall: 1.0\n",
      "F1-Score: 0.9968847352024921\n",
      "\n",
      "Class: 32\n",
      "Precision: 0.9761904761904762\n",
      "Recall: 1.0\n",
      "F1-Score: 0.9879518072289156\n",
      "\n",
      "Class: 33\n",
      "Precision: 0.9785714285714285\n",
      "Recall: 0.9927536231884058\n",
      "F1-Score: 0.9856115107913668\n",
      "\n",
      "Class: 34\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Class: 35\n",
      "Precision: 0.9955156950672646\n",
      "Recall: 0.9910714285714286\n",
      "F1-Score: 0.9932885906040269\n",
      "\n",
      "Class: 36\n",
      "Precision: 1.0\n",
      "Recall: 0.9875\n",
      "F1-Score: 0.9937106918238994\n",
      "\n",
      "Class: 37\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Class: 38\n",
      "Precision: 0.9975786924939467\n",
      "Recall: 0.9856459330143541\n",
      "F1-Score: 0.9915764139590855\n",
      "\n",
      "Class: 39\n",
      "Precision: 1.0\n",
      "Recall: 0.9827586206896551\n",
      "F1-Score: 0.9913043478260869\n",
      "\n",
      "Class: 40\n",
      "Precision: 1.0\n",
      "Recall: 0.9666666666666667\n",
      "F1-Score: 0.983050847457627\n",
      "\n",
      "Class: 41\n",
      "Precision: 1.0\n",
      "Recall: 0.9574468085106383\n",
      "F1-Score: 0.9782608695652174\n",
      "\n",
      "Class: 42\n",
      "Precision: 1.0\n",
      "Recall: 0.975609756097561\n",
      "F1-Score: 0.9876543209876543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.Split the Data and Train the model and evaluating - HOG - Random Forest\n",
    "#random Forest for HOG_Features\n",
    "X_train_forest_hog, X_test_forest_hog, y_train_forest_hog, y_test_forest_hog = train_test_split(X_hog, y_hog, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_forest_hog = scaler.fit_transform(X_train_forest_hog)\n",
    "X_test_scaled_forest_hog = scaler.transform(X_test_forest_hog)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "random_forest_hog = RandomForestClassifier()\n",
    "random_forest_hog.fit(X_train_scaled_forest_hog, y_train_forest_hog)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_forest_hog = random_forest_hog.predict(X_test_scaled_forest_hog)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_forest_hog = accuracy_score(y_test_forest_hog, y_pred_forest_hog)\n",
    "print(\"Accuracy for Random Forest:\", accuracy_forest_hog)\n",
    "print()\n",
    "\n",
    "# Calculating precision, recall, and F1-score for each class\n",
    "precision_forest_hog = precision_score(y_test_forest_hog, y_pred_forest_hog, average=None)\n",
    "recall_forest_hog = recall_score(y_test_forest_hog, y_pred_forest_hog, average=None)\n",
    "f1_forest_hog = f1_score(y_test_forest_hog, y_pred_forest_hog, average=None)\n",
    "\n",
    "# Printing the evaluation metrics for each class\n",
    "for class_label, prec, rec, f1_score_rf1 in zip(np.unique(y_hog), precision_forest_hog, recall_forest_hog, f1_forest_hog):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F1-Score: {f1_score_rf1}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ea0a6d-9fa0-4a63-94b2-87201d246d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for a SVM: 0.9802346340219332\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m precision_svm_hog \u001b[38;5;241m=\u001b[39m precision_score(y_test_svm_hog, y_pred_svm_hog, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m recall_svm_hog \u001b[38;5;241m=\u001b[39m recall_score(y_test_svm_hog, y_pred_svm_hog, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m f1_svm_hog \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_svm_hog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_svm_hog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Printing the evaluation metrics for each class\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_label, prec, rec, f1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_hog), precision_svm_hog, recall_svm_hog, f1_svm_hog):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "# 6.Split the Data and Train the model and evaluating - HOG - Support Vector Machine\n",
    "#SVM for HOG_Features\n",
    "X_train_svm_hog, X_test_svm_hog, y_train_svm_hog, y_test_svm_hog = train_test_split(X_hog, y_hog, test_size=0.2, random_state=42)\n",
    "\n",
    "clf_hog= make_pipeline(StandardScaler(),SVC(kernel=\"rbf\", gamma= \"auto\"))\n",
    "clf_hog.fit(X_train_svm_hog,y_train_svm_hog)\n",
    "y_pred_svm_hog = clf_hog.predict(X_test_svm_hog)\n",
    "accuracy_svm_hog = accuracy_score(y_test_svm_hog, y_pred_svm_hog)\n",
    "print(\"Accuracy for a SVM:\", accuracy_svm_hog)\n",
    "print()\n",
    "\n",
    "# Calculating precision, recall, and F1-score for each class\n",
    "precision_svm_hog = precision_score(y_test_svm_hog, y_pred_svm_hog, average=None)\n",
    "recall_svm_hog = recall_score(y_test_svm_hog, y_pred_svm_hog, average=None)\n",
    "f1_svm_hog = f1_score(y_test_svm_hog, y_pred_svm_hog, average=None)\n",
    "\n",
    "# Printing the evaluation metrics for each class\n",
    "for class_label, prec, rec, f1_score_svm1  in zip(np.unique(y_hog), precision_svm_hog, recall_svm_hog, f1_svm_hog):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F1-Score: {f1_score_svm1}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f84a34e-1442-4572-b7a2-155d267e908e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(X), np\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[1;32m     38\u001b[0m folder_path_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jovyan/ML Projekkkkt/App.ML/dataset_folder_train_images/GTSRB/Final_Training/Images\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 40\u001b[0m X_hue,y_hue \u001b[38;5;241m=\u001b[39m \u001b[43mread_data_HUE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m, in \u001b[0;36mread_data_HUE\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m desired_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m43\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     class_folder \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, \u001b[38;5;28mstr\u001b[39m(class_label))\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(class_folder):\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.ppm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# 7.Extracting the HUE Features\n",
    "def read_data_HUE(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    desired_width = 29\n",
    "    desired_height = 30\n",
    "\n",
    "    for class_label in range(43):\n",
    "        class_folder = os.path.join(folder_path, str(class_label))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for file_name in os.listdir(class_folder):\n",
    "            if file_name.endswith(\".ppm\"):\n",
    "                file_path = os.path.join(class_folder, file_name)\n",
    "                \n",
    "                \n",
    "            \n",
    "                image = cv2.imread(file_path)\n",
    "                scaled_image = cv2.resize(image, (desired_width, desired_height)) \n",
    "                image_hsv = cv2.cvtColor(scaled_image, cv2.COLOR_BGR2HSV) \n",
    "                \n",
    "                border_size = 5\n",
    "                image_hsv_cropped = image_hsv[border_size:-border_size, border_size:-border_size] \n",
    "                hue_values = image_hsv_cropped[:, :, 0].flatten()\n",
    "                \n",
    "                histogram, _ = np.histogram(hue_values, bins=256, range=[0, 256])\n",
    "                normalized_histogram = histogram.astype(np.float64) / np.sum(histogram)\n",
    "                dimensionality = len(normalized_histogram)\n",
    "               \n",
    "                \n",
    "                X.append(hue_values)\n",
    "                y.append(class_label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "folder_path_train = \"/home/jovyan/ML Projekkkkt/App.ML/dataset_folder_train_images/GTSRB/Final_Training/Images\"\n",
    "\n",
    "X_hue,y_hue = read_data_HUE(folder_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f60ba53-ad18-4a9f-9347-42719475e5bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 8.Split the Data and Train the model and evaluating - HUE - Random Forest\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#random Forest for HUE features\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m X_train_forest_hue, X_test_forest_hue, y_train_forest_hue, y_test_forest_hue \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(X_hue, y_hue, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m      5\u001b[0m X_train_scaled_forest_hue \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train_forest_hue)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# 8.Split the Data and Train the model and evaluating - HUE - Random Forest\n",
    "#random Forest for HUE features\n",
    "X_train_forest_hue, X_test_forest_hue, y_train_forest_hue, y_test_forest_hue = train_test_split(X_hue, y_hue, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_forest_hue = scaler.fit_transform(X_train_forest_hue)\n",
    "X_test_scaled_forest_hue = scaler.transform(X_test_forest_hue)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "random_forest_hue = RandomForestClassifier()\n",
    "random_forest_hue.fit(X_train_scaled_forest_hue, y_train_forest_hue)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_forest_hue = random_forest_hue.predict(X_test_scaled_forest_hue)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_forest_hue = accuracy_score(y_test_forest_hue, y_pred_forest_hue)\n",
    "print(\"Accuracy for Random Forest:\", accuracy_forest_hue)\n",
    "print()\n",
    "\n",
    "# Calculating precision, recall, and F1-score for each class\n",
    "precision_forest_hue = precision_score(y_test_forest_hue, y_pred_forest_hue, average=None)\n",
    "recall_forest_hue = recall_score(y_test_forest_hue, y_pred_forest_hue, average=None)\n",
    "f1_forest_hue = f1_score(y_test_forest_hue, y_pred_forest_hue, average=None)\n",
    "\n",
    "# Printing the evaluation metrics for each class\n",
    "for class_label, prec, rec, f1_score_rf2 in zip(np.unique(y_hue), precision_forest_hue, recall_forest_hue, f1_forest_hue):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F1-Score: {f1_score_rf2}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cec566-68d2-4246-b512-7e36cdcda6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.Split the Data and Train the model and evaluating - HUE - Support Vector Machine\n",
    "#SVM for HUE features\n",
    "X_train_svm_hue, X_test_svm_hue, y_train_svm_hue, y_test_svm_hue = train_test_split(X_hue, y_hue, test_size=0.2, random_state=42)\n",
    "\n",
    "clf_hue= make_pipeline(StandardScaler(),SVC(kernel=\"rbf\", gamma= \"auto\"))\n",
    "clf_hue.fit(X_train_svm_hue,y_train_svm_hue)\n",
    "y_pred_svm_hue = clf_hue.predict(X_test_svm_hue)\n",
    "accuracy_svm_hue = accuracy_score(y_test_svm_hue, y_pred_svm_hue)\n",
    "print(\"Accuracy for a SVM:\", accuracy_svm_hue)\n",
    "print()\n",
    "\n",
    "# Calculating precision, recall, and F1-score for each class\n",
    "precision_svm_hue = precision_score(y_test_svm_hue, y_pred_svm_hue, average=None)\n",
    "recall_svm_hue = recall_score(y_test_svm_hue, y_pred_svm_hue, average=None)\n",
    "f1_svm_hue = f1_score(y_test_svm_hue, y_pred_svm_hue, average=None)\n",
    "\n",
    "# Printing the evaluation metrics for each class\n",
    "for class_label, prec, rec, f1_score_svm2 in zip(np.unique(y_hue), precision_svm_hue, recall_svm_hue, f1_svm_hue):\n",
    "    print(f\"Class: {class_label}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F1-Score: {f1_score_svm2}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
